{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name(s) Group:\n",
    "# Class: Knowledge Discovery and Data Mining\n",
    "# Date: Summer 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees and Random Forest Models applied to LendingClub data set \n",
    "\n",
    "## Knowledge Discovery in Databases - Data Mining\n",
    "## DIRECTIONS\n",
    "### Review all code and markdown.  Provide responses to questions at the end of the notebook (markdown, code)\n",
    "### Turn in this notebook via Canvas in the assignment area\n",
    "\n",
    "For this exercise, we will be exploring publicly available data from [LendingClub.com](www.lendingclub.com). Lending Club connects people who need money (borrowers) with people who have money (investors). We try to create a model to predict the risk of lending money to someone given a wide range of credit related data. We will use lending data from 2007-2010 and be trying to classify and predict **whether or not the borrower paid back their loan in full.**\n",
    "\n",
    "Here are what the columns in the data set represent:\n",
    "\n",
    "* **credit.policy**: 1 if the customer meets the credit underwriting criteria of LendingClub.com, and 0 otherwise.\n",
    "* **purpose**: The purpose of the loan (takes values \"credit_card\", \"debt_consolidation\", \"educational\", \"major_purchase\", \"small_business\", and \"all_other\").\n",
    "* **int.rate**: The interest rate of the loan, as a proportion (a rate of 11% would be stored as 0.11). Borrowers judged by LendingClub.com to be more risky are assigned higher interest rates.\n",
    "* **installment**: The monthly installments owed by the borrower if the loan is funded.\n",
    "* **log.annual.inc**: The natural log of the self-reported annual income of the borrower.\n",
    "* **dti**: The debt-to-income ratio of the borrower (amount of debt divided by annual income).\n",
    "* **fico**: The FICO credit score of the borrower.\n",
    "* **days.with.cr.line**: The number of days the borrower has had a credit line.\n",
    "* **revol.bal**: The borrower's revolving balance (amount unpaid at the end of the credit card billing cycle).\n",
    "* **revol.util**: The borrower's revolving line utilization rate (the amount of the credit line used relative to total credit available).\n",
    "* **inq.last.6mths**: The borrower's number of inquiries by creditors in the last 6 months.\n",
    "* **delinq.2yrs**: The number of times the borrower had been 30+ days past due on a payment in the past 2 years.\n",
    "* **pub.rec**: The borrower's number of derogatory public records (bankruptcy filings, tax liens, or judgments).\n",
    "* **not.fully.paid**: The quantity of interest for classification - whether the borrower paid back the money in full or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries and data set\n",
    "\n",
    "**Import the usual libraries for pandas and plotting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Data\n",
    "\n",
    "** Use pandas to read loan_data.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('loan_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out the info(), head(), and describe() methods on loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Following is a analysis of credit approval status. 1 means approved credit, 0 means not approved.\")\n",
    "print(df['credit.policy'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of FICO scores by credit approval status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['credit.policy']==1]['fico'].plot.hist(bins=30,alpha=0.5,color='blue', label='Credit.Policy=1')\n",
    "df[df['credit.policy']==0]['fico'].plot.hist(bins=30,alpha=0.5, color='red', label='Credit.Policy=0')\n",
    "plt.legend(fontsize=15)\n",
    "plt.title (\"Histogram of FICO score by approved or disapproved credit policies\", fontsize=16)\n",
    "plt.xlabel(\"FICO score\", fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Presence or absence of statistical difference of various factors between credit approval status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=df['credit.policy'],y=df['int.rate'])\n",
    "plt.title(\"Interest rate varies between risky and non-risky borrowers\", fontsize=15)\n",
    "plt.xlabel(\"Credit policy\",fontsize=15)\n",
    "plt.ylabel(\"Interest rate\",fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df['credit.policy'],y=df['log.annual.inc'])\n",
    "plt.title(\"Income level does not make a big difference in credit approval odds\", fontsize=15)\n",
    "plt.xlabel(\"Credit policy\",fontsize=15)\n",
    "plt.ylabel(\"Log. annual income\",fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df['credit.policy'],y=df['days.with.cr.line'])\n",
    "plt.title(\"Credit-approved users have a slightly higher days with credit line\", fontsize=15)\n",
    "plt.xlabel(\"Credit policy\",fontsize=15)\n",
    "plt.ylabel(\"Days with credit line\",fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df['credit.policy'],y=df['dti'])\n",
    "plt.title(\"Debt-to-income level does not make a big difference in credit approval odds\", fontsize=15)\n",
    "plt.xlabel(\"Credit policy\",fontsize=15)\n",
    "plt.ylabel(\"Debt-to-income ratio\",fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Countplot bar chart of loans by purpose, with the color hue defined by not.fully.paid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.countplot(x='purpose',hue='not.fully.paid',data=df, palette='Set1')\n",
    "plt.title(\"Bar chart of loan purpose colored by not fully paid status\", fontsize=17)\n",
    "plt.xlabel(\"Purpose\", fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trend between FICO score and interest rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='fico',y='int.rate',data=df, color='purple', size=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LM plot to see if the trend differed between not.fully.paid and credit.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,7))\n",
    "sns.lmplot(y='int.rate',x='fico',data=df,hue='credit.policy',\n",
    "           col='not.fully.paid',palette='Set1',size=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the Data\n",
    "## Categorical Features\n",
    "\n",
    "The **purpose** column as categorical. We transform them using dummy variables so sklearn will be able to understand them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.get_dummies(df,['purpose'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "For supervised learning we are predicting whether or not the borrower will or has paid their load in full based on not.fully.paid.  The train - test split is 70% 30%.  We will train on 70% of the data which includes the target variable.  We will then use the model to predict the test set.\n",
    "\n",
    "While we did not deal with missing values, remember to adjust missing values on the train set only - using information from the test set will cause overfitting (or may cause overfitting). This means the prediction is very accurate (of course, you are using all of the data which represents the future data) but then when you try to apply your model to actual new data the accuracy can be poor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df_final.drop('not.fully.paid',axis=1)\n",
    "y = df_final['not.fully.paid']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create an instance of DecisionTreeClassifier() called dtree and fit it to the training data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier(criterion='gini',max_depth=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions and Evaluation of Decision Tree\n",
    "**Create predictions from the test set and create a classification report and a confusion matrix.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dtree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test,predictions)\n",
    "print(cm)\n",
    "print (\"Accuracy of prediction:\",round((cm[0,0]+cm[1,1])/cm.sum(),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Random Forest model\n",
    "\n",
    "Now its time to train our model random forest.\n",
    "Why is this better?  Random Forest represents an ensemble method of learning - this helps to avoid overfitting which was described earlier.  Ensemble methods create not one but many models (many decision trees) and then take generally the mode of the results in order to improve the model accuracy for new data and avoid overfitting.  We like to say with random forest \"Nobody knows everything, but everybody knows something\" - we can use the benefit of multiple models to learn even more and improve our predictive capabilities on new data.  \n",
    "\n",
    "Many like to say that Random Forest is what you try first for supervised learning.  It is almost always a good choice. WHY?\n",
    "1)  it can solve classification and regression problems\n",
    "2)  It can handle all types of input without need for scaling - binary, categorical, numerical, etc.\n",
    "3)  It does not require alot of tweaking of parameters to get the best results\n",
    "4)  it handles missing data well\n",
    "\n",
    "So . . . is it a SILVER BULLET?  no, in fact it can seem like a black box for those that like to dig deep into tyhe statistics. \n",
    "\n",
    "**Create an instance of the RandomForestClassifier class and fit it to our training data from the previous step.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions and Evaluation\n",
    "\n",
    "Let's predict the y_test values and evaluate our model.\n",
    "\n",
    "** Predict the class of not.fully.paid for the X_test data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now create a classification report from the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show the Confusion Matrix for the predictions.**\n",
    "\n",
    "A confusion  matrix is a way to evaluate your results along with the classification report.  Here is some more info:  <a href=\"https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/\"> Data School Confusion Matrix Explanation</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,rfc_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Running a loop with increasing number of trees in the random forest and checking accuracy of confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Criterion 'gini' or 'entropy'**\n",
    "\n",
    "Your text describes how decision trees are constructed using entropy and information gain.  Entropy is a measure of randomness - we pick decision tree splits where the randomness is less (we are more certain of the outcome).  If we are completely certain of an outcome entropy is 0, if we are 50-50 split on the outcome entropy is 1.\n",
    "\n",
    "As we partition the decision tree we try to reduce the disorder or entropy and the result is the information gain of understanding the tree.  We chose the splits where the information gain is the largest.  Here is a short explanation:  <a href=\"https://www.youtube.com/watch?v=7VeUPuFGJHk\">Decision Trees, entropy and info gain</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using gini index first\n",
    "nsimu = 21\n",
    "accuracy=[0]*nsimu\n",
    "ntree = [0]*nsimu\n",
    "for i in range(1,nsimu):\n",
    "    rfc = RandomForestClassifier(n_estimators=i*5,min_samples_split=10,max_depth=None,criterion='gini')\n",
    "    rfc.fit(X_train, y_train)\n",
    "    rfc_pred = rfc.predict(X_test)\n",
    "    cm = confusion_matrix(y_test,rfc_pred)\n",
    "    accuracy[i] = (cm[0,0]+cm[1,1])/cm.sum()\n",
    "    ntree[i]=i*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the results\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(x=ntree[1:nsimu],y=accuracy[1:nsimu],s=60,c='red')\n",
    "plt.title(\"Number of trees in the Random Forest vs. prediction accuracy (criterion: 'gini')\", fontsize=18)\n",
    "plt.xlabel(\"Number of trees\", fontsize=15)\n",
    "plt.ylabel(\"Prediction accuracy from confusion matrix\", fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using entropy\n",
    "nsimu = 21\n",
    "accuracy=[0]*nsimu\n",
    "ntree = [0]*nsimu\n",
    "for i in range(1,nsimu):\n",
    "    rfc = RandomForestClassifier(n_estimators=i*5,min_samples_split=10,max_depth=None,criterion='entropy')\n",
    "    rfc.fit(X_train, y_train)\n",
    "    rfc_pred = rfc.predict(X_test)\n",
    "    cm = confusion_matrix(y_test,rfc_pred)\n",
    "    accuracy[i] = (cm[0,0]+cm[1,1])/cm.sum()\n",
    "    ntree[i]=i*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the results\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(x=ntree[1:nsimu],y=accuracy[1:nsimu],s=60,c='red')\n",
    "plt.title(\"Number of trees in the Random Forest vs. prediction accuracy (criterion: 'entropy')\", fontsize=18)\n",
    "plt.xlabel(\"Number of trees\", fontsize=15)\n",
    "plt.ylabel(\"Prediction accuracy from confusion matrix\", fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fixing max tree depth**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsimu = 21\n",
    "accuracy=[0]*nsimu\n",
    "ntree = [0]*nsimu\n",
    "for i in range(1,nsimu):\n",
    "    rfc = RandomForestClassifier(n_estimators=i*5,min_samples_split=10,max_depth=None,criterion='gini')\n",
    "    rfc.fit(X_train, y_train)\n",
    "    rfc_pred = rfc.predict(X_test)\n",
    "    cm = confusion_matrix(y_test,rfc_pred)\n",
    "    accuracy[i] = (cm[0,0]+cm[1,1])/cm.sum()\n",
    "    ntree[i]=i*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(x=ntree[1:nsimu],y=accuracy[1:nsimu],s=60,c='red')\n",
    "plt.title(\"Number of trees in the Random Forest vs. prediction accuracy (max depth: None)\", fontsize=18)\n",
    "plt.xlabel(\"Number of trees\", fontsize=15)\n",
    "plt.ylabel(\"Prediction accuracy from confusion matrix\", fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsimu = 21\n",
    "accuracy=[0]*nsimu\n",
    "ntree = [0]*nsimu\n",
    "for i in range(1,nsimu):\n",
    "    rfc = RandomForestClassifier(n_estimators=i*5,min_samples_split=10,max_depth=5,criterion='gini')\n",
    "    rfc.fit(X_train, y_train)\n",
    "    rfc_pred = rfc.predict(X_test)\n",
    "    cm = confusion_matrix(y_test,rfc_pred)\n",
    "    accuracy[i] = (cm[0,0]+cm[1,1])/cm.sum()\n",
    "    ntree[i]=i*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(x=ntree[1:nsimu],y=accuracy[1:nsimu],s=60,c='red')\n",
    "plt.title(\"Number of trees in the Random Forest vs. prediction accuracy (max depth: 5)\", fontsize=18)\n",
    "plt.xlabel(\"Number of trees\", fontsize=15)\n",
    "plt.ylabel(\"Prediction accuracy from confusion matrix\", fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Minimum sample split criteria**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsimu = 21\n",
    "accuracy=[0]*nsimu\n",
    "ntree = [0]*nsimu\n",
    "for i in range(1,nsimu):\n",
    "    rfc = RandomForestClassifier(n_estimators=i*5,min_samples_split=2,max_depth=None,criterion='gini')\n",
    "    rfc.fit(X_train, y_train)\n",
    "    rfc_pred = rfc.predict(X_test)\n",
    "    cm = confusion_matrix(y_test,rfc_pred)\n",
    "    accuracy[i] = (cm[0,0]+cm[1,1])/cm.sum()\n",
    "    ntree[i]=i*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(x=ntree[1:nsimu],y=accuracy[1:nsimu],s=60,c='red')\n",
    "plt.title(\"Number of trees in the Random Forest vs. prediction accuracy (minimum sample split: 2)\", fontsize=18)\n",
    "plt.xlabel(\"Number of trees\", fontsize=15)\n",
    "plt.ylabel(\"Prediction accuracy from confusion matrix\", fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsimu = 21\n",
    "accuracy=[0]*nsimu\n",
    "ntree = [0]*nsimu\n",
    "for i in range(1,nsimu):\n",
    "    rfc = RandomForestClassifier(n_estimators=i*5,min_samples_split=20,max_depth=None,criterion='gini')\n",
    "    rfc.fit(X_train, y_train)\n",
    "    rfc_pred = rfc.predict(X_test)\n",
    "    cm = confusion_matrix(y_test,rfc_pred)\n",
    "    accuracy[i] = (cm[0,0]+cm[1,1])/cm.sum()\n",
    "    ntree[i]=i*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(x=ntree[1:nsimu],y=accuracy[1:nsimu],s=60,c='red')\n",
    "plt.title(\"Number of trees in the Random Forest vs. prediction accuracy (minimum sample split: 20)\", fontsize=18)\n",
    "plt.xlabel(\"Number of trees\", fontsize=15)\n",
    "plt.ylabel(\"Prediction accuracy from confusion matrix\", fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTIONS:\n",
    "1.  Evaluate the decision tree classification report and confusion matrix in your own words.\n",
    "2.  Did the Random Forest Model show improvement in the prediction accuracy based on the final chart?  \n",
    "3.  Why is Random Forest better for this predictive model than the basic Decision Tree?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
